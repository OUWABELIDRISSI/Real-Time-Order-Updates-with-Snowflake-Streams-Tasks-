# Pipeline dâ€™Ã©vÃ©nements de commandes en temps rÃ©el avec Snowflake

## ğŸš€ PrÃ©sentation du projet
Ce projet dÃ©montre la mise en place dâ€™un **pipeline de donnÃ©es temps rÃ©el** entiÃ¨rement basÃ© sur **Snowflake**.

Il permet dâ€™ingÃ©rer des Ã©vÃ©nements de commandes e-commerce au format JSON, de les transformer de maniÃ¨re incrÃ©mentale et de fournir des tables prÃªtes pour lâ€™analyse.

Ce dÃ©pÃ´t est conÃ§u pour mettre en valeur des **compÃ©tences concrÃ¨tes en data engineering Snowflake**.

---

## ğŸ§± Stack technique
- Snowflake
- SQL
- JSON / JSON Lines
- Snowflake Streams & Tasks

---

## ğŸ“‚ Structure du projet
```text
â”œâ”€â”€ data/
â”‚ â””â”€â”€ orders_events.jsonl
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ 01_setup.sql
â”‚ â”œâ”€â”€ 02_raw_layer.sql
â”‚ â”œâ”€â”€ 03_streams.sql
â”‚ â”œâ”€â”€ 04_transform.sql
â”‚ â”œâ”€â”€ 05_tasks.sql
â”‚ â””â”€â”€ 06_queries.sql
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ architecture.md
â””â”€â”€ README.md
```
---

## ğŸ—ï¸ Architecture
Le pipeline suit un **pattern ELT moderne** :
- Ingestion des donnÃ©es brutes
- Traitement incrÃ©mental via Streams
- Transformations automatisÃ©es via Tasks
- Tables analytiques prÃªtes Ã  lâ€™usage

ğŸ“˜ DÃ©tails complets : `docs/architecture.md`

---

## ğŸ”„ Ã‰tapes du pipeline

1. DÃ©pÃ´t des fichiers JSON Lines dans un stage Snowflake
2. Chargement des Ã©vÃ©nements dans la couche raw
3. DÃ©tection des nouvelles donnÃ©es via un stream
4. Transformation automatique vers la couche analytics
5. Analyse via requÃªtes SQL

---

## ğŸ“Š Cas dâ€™usage
- Suivi du chiffre dâ€™affaires journalier
- Analyse de la valeur client
- Suivi du cycle de vie des commandes
- DÃ©tection dâ€™Ã©vÃ©nements tardifs
- Alimentation de dashboards temps rÃ©el

---

## â–¶ï¸ ExÃ©cution du projet

1. CrÃ©ation de lâ€™infrastructure Snowflake :
```sql
-- ExÃ©cuter sql/01_setup.sql
```
2. CrÃ©ation de la couche raw et du stream :
```sql
-- ExÃ©cuter sql/02_raw_layer.sql
-- ExÃ©cuter sql/03_streams.sql
```
3. CrÃ©ation de la table analytics :
```sql
-- ExÃ©cuter sql/04_transform.sql
```
4. Activation du traitement automatique :
```sql
-- ExÃ©cuter sql/05_tasks.sql
```
5. RequÃªtes analytiques :
```sql
-- ExÃ©cuter sql/06_queries.sql
```

## ğŸ¯ Objectifs du projet

Ce projet met en Ã©vidence :

- Lâ€™ingestion temps rÃ©el
- Les capacitÃ©s natives de Snowflake
- Le traitement incrÃ©mental
- Une modÃ©lisation orientÃ©e analytique
- Des pratiques proches de la production


## ğŸ“Œ Ã‰volutions possibles

- Auto-ingestion avec Snowpipe
- ContrÃ´les de qualitÃ© des donnÃ©es
- Optimisation des coÃ»ts
- IntÃ©gration dâ€™outils BI
- CI/CD pour le SQL